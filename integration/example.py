"""
LERK System Integration Example

This example demonstrates the clean integration between clustering,
consolidation, and retriever modules using the integration layer.
"""

import asyncio
import logging
from typing import Dict, Any, List

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def demonstrate_clean_integration():
    """Demonstrate clean integration between modules."""
    print("ğŸ”— LERK System Clean Integration Demonstration")
    print("=" * 60)
    
    try:
        # Import the integration manager
        from integration import (
            LERKIntegrationManager,
            create_integration_manager,
            process_documents_with_integration
        )
        
        # Import individual modules
        from clustering import DynamicClusteringManager
        from consolidation import ClusterBasedSubjectConsolidator
        from retriever import SubjectRetriever
        
        print("\nğŸ“‹ Step 1: Initialize Module Managers")
        print("-" * 40)
        
        # Create individual module managers
        clustering_manager = DynamicClusteringManager()
        consolidation_manager = ClusterBasedSubjectConsolidator()
        retriever_manager = SubjectRetriever()
        
        print("âœ… Clustering manager initialized")
        print("âœ… Consolidation manager initialized") 
        print("âœ… Retriever manager initialized")
        
        print("\nğŸ”— Step 2: Create Integration Manager")
        print("-" * 40)
        
        # Create integration manager
        integration_manager = create_integration_manager(
            clustering_manager=clustering_manager,
            consolidation_manager=consolidation_manager,
            retriever_manager=retriever_manager
        )
        
        print("âœ… Integration manager created")
        
        # Check integration status
        status = integration_manager.get_integration_status()
        print(f"ğŸ“Š Integration health: {status['integration_health']}")
        print(f"ğŸ“Š Managers available: {status['managers_available']}")
        
        print("\nğŸ“„ Step 3: Prepare Sample Data")
        print("-" * 40)
        
        # Create sample documents
        new_documents = [
            {
                "document_id": "doc_001",
                "content": "Machine learning algorithms can be supervised or unsupervised.",
                "file_type": "text"
            },
            {
                "document_id": "doc_002", 
                "content": "Deep learning uses neural networks with multiple layers.",
                "file_type": "text"
            },
            {
                "document_id": "doc_003",
                "content": "Natural language processing helps computers understand human language.",
                "file_type": "text"
            }
        ]
        
        # Create sample document knowledge map
        document_knowledge_map = {
            "doc_001": {
                "document_id": "doc_001",
                "core_concepts": ["machine learning", "algorithms", "supervised", "unsupervised"],
                "key_insights": ["ML algorithms can be categorized by learning type"]
            },
            "doc_002": {
                "document_id": "doc_002",
                "core_concepts": ["deep learning", "neural networks", "layers"],
                "key_insights": ["Deep learning uses multi-layer neural networks"]
            },
            "doc_003": {
                "document_id": "doc_003", 
                "core_concepts": ["natural language processing", "computers", "human language"],
                "key_insights": ["NLP enables computer understanding of human language"]
            }
        }
        
        print(f"âœ… Created {len(new_documents)} sample documents")
        print(f"âœ… Created document knowledge map with {len(document_knowledge_map)} entries")
        
        print("\nâš¡ Step 4: Process Documents Through Integration Pipeline")
        print("-" * 40)
        
        # Process documents through the complete integration pipeline
        integration_results = await integration_manager.process_new_documents_integrated(
            new_documents=new_documents,
            document_knowledge_map=document_knowledge_map,
            update_strategy="auto"
        )
        
        print(f"âœ… Integration processing completed: {integration_results['success']}")
        
        # Display results
        print("\nğŸ“Š Step 5: Integration Results")
        print("-" * 40)
        
        clustering_results = integration_results.get("clustering_results", {})
        consolidation_results = integration_results.get("consolidation_results", {})
        retriever_notification = integration_results.get("retriever_notification", {})
        
        print(f"ğŸ”µ Clustering Results:")
        print(f"   - Success: {clustering_results.get('success', False)}")
        print(f"   - Strategy: {clustering_results.get('strategy', 'unknown')}")
        print(f"   - New clusters: {clustering_results.get('clustering_changes', {}).get('new_clusters', 0)}")
        print(f"   - Updated clusters: {clustering_results.get('clustering_changes', {}).get('updated_clusters', 0)}")
        
        print(f"\nğŸŸ¢ Consolidation Results:")
        print(f"   - Updated subjects: {len(consolidation_results.get('updated_subjects', []))}")
        print(f"   - New subjects: {len(consolidation_results.get('new_subjects', []))}")
        print(f"   - Deleted subjects: {len(consolidation_results.get('deleted_subjects', []))}")
        
        print(f"\nğŸŸ¡ Retriever Notification:")
        print(f"   - Success: {retriever_notification.get('success', False)}")
        print(f"   - Cache updated: {retriever_notification.get('cache_updated', False)}")
        print(f"   - Indices refreshed: {retriever_notification.get('indices_refreshed', False)}")
        
        if integration_results.get("errors"):
            print(f"\nâš ï¸  Errors:")
            for error in integration_results["errors"]:
                print(f"   - {error}")
        
        print("\nğŸ¯ Step 6: Demonstrate Individual Module Interfaces")
        print("-" * 40)
        
        # Demonstrate individual module interfaces
        from integration import (
            ClusteringIntegrationInterface,
            ConsolidationIntegrationInterface,
            RetrieverIntegrationInterface
        )
        
        # Test clustering interface
        print("ğŸ”µ Testing Clustering Interface:")
        clustering_interface_results = await ClusteringIntegrationInterface.process_documents_for_clustering(
            new_documents[:2], "incremental"
        )
        print(f"   - Clustering interface success: {clustering_interface_results.get('success', False)}")
        
        # Test consolidation interface
        print("\nğŸŸ¢ Testing Consolidation Interface:")
        consolidation_interface_results = await ConsolidationIntegrationInterface.handle_clustering_updates(
            clustering_results, document_knowledge_map
        )
        print(f"   - Consolidation interface success: {not consolidation_interface_results.get('error')}")
        
        # Test retriever interface
        print("\nğŸŸ¡ Testing Retriever Interface:")
        retriever_interface_results = RetrieverIntegrationInterface.search_subject_knowledge(
            "machine learning concepts"
        )
        print(f"   - Retriever interface results: {len(retriever_interface_results)} results")
        
        print("\nâœ… Clean Integration Demonstration Completed Successfully!")
        print("=" * 60)
        
        return integration_results
        
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        print("Make sure all modules are properly installed and available")
        return None
    except Exception as e:
        print(f"âŒ Demonstration failed: {e}")
        logger.error(f"Integration demonstration failed: {e}")
        return None


async def demonstrate_convenience_function():
    """Demonstrate the convenience function for integrated processing."""
    print("\nğŸš€ Convenience Function Demonstration")
    print("=" * 50)
    
    try:
        from integration import process_documents_with_integration
        
        # Sample data
        documents = [
            {"document_id": "conv_001", "content": "Artificial intelligence is transforming industries."},
            {"document_id": "conv_002", "content": "Machine learning models require training data."}
        ]
        
        knowledge_map = {
            "conv_001": {"document_id": "conv_001", "concepts": ["AI", "industries"]},
            "conv_002": {"document_id": "conv_002", "concepts": ["ML", "training", "data"]}
        }
        
        # Process using convenience function
        results = await process_documents_with_integration(
            new_documents=documents,
            document_knowledge_map=knowledge_map,
            update_strategy="hybrid"
        )
        
        print(f"âœ… Convenience function completed: {results.get('success', False)}")
        print(f"ğŸ“Š Clustering success: {results.get('clustering_results', {}).get('success', False)}")
        
        return results
        
    except Exception as e:
        print(f"âŒ Convenience function failed: {e}")
        return None


if __name__ == "__main__":
    print("Starting LERK System Integration Examples...")
    
    # Run the demonstrations
    asyncio.run(demonstrate_clean_integration())
    asyncio.run(demonstrate_convenience_function())
    
    print("\nğŸ‰ All integration examples completed!")
